# scrapers/atica.py
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import re, sys, time, unicodedata
import cloudscraper
from bs4 import BeautifulSoup
from utils import (
    HEADERS,
    LOCALIZACIONES_DESEADAS,
    HABITACIONES_MINIMAS,
    limpiar_y_convertir_a_numero,
)

LISTADO_URL = (
    "https://grupo-atica.com/propiedades/public/"
    "?obranueva_viviendas=2&order=&quantity=&disposicion=listado"
    "&tipologia=&comprar_alquilar=&tipo_inmueble=0"
    "&provincia=Valencia&localidad=&habitaciones=&banyos="
    "&price=0%2C270000"
)

# â”€â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _norm(texto: str) -> str:
    """MinÃºsculas sin acentos, sin espacios de extremos."""
    return (
        unicodedata.normalize("NFKD", texto)
        .encode("ascii", "ignore")
        .decode()
        .lower()
        .strip()
    )

# â”€â”€â”€ scraper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def scrape() -> list[str]:
    scraper = cloudscraper.create_scraper(
        browser={"browser": "firefox", "platform": "windows", "mobile": False}
    )
    try:
        html = scraper.get(LISTADO_URL, headers=HEADERS, timeout=30).text
    except Exception as exc:
        print(f"âš ï¸  Ãtica: error al descargar la pÃ¡gina â†’ {exc}", file=sys.stderr)
        return []

    soup  = BeautifulSoup(html, "html.parser")
    cards = soup.select("div.item-vivienda")
    print(f"[DEBUG] ÃTICA â†’ {len(cards)} tarjetas totales", flush=True)

    resultados: list[str] = []

    for card in cards:
        # â”€ Nombre â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        name_tag = card.find("h3")
        nombre = name_tag.get_text(" ", strip=True) if name_tag else "SIN NOMBRE"

        # â”€ UbicaciÃ³n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        loc_tag = card.find("div", class_=re.compile(r"\bcol-md-7\b"))
        ubic_raw = loc_tag.get_text(" ", strip=True) if loc_tag else ""
        #   Cortamos en el primer separador (.,Â·,-,|)
        municipio_raw = re.split(r"[.\-Â·|]", ubic_raw, maxsplit=1)[0]
        municipio_norm = _norm(municipio_raw)

        #   Â¿estÃ¡ en la lista de deseos?
        if not any(_norm(loc) in municipio_norm for loc in LOCALIZACIONES_DESEADAS):
            continue

        # â”€ Enlace â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        link = card.select_one("a.cont[href]")
        url_promo = link["href"] if link else LISTADO_URL

        # â”€ â€œNuevo proyectoâ€ flag â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        badge = card.find("span", class_=re.compile("badge"))
        es_nuevo = badge and "nuevo proyecto" in badge.get_text(strip=True).lower()

        # â”€ Dormitorios (atributo data-numhabitaciones) â”€â”€â”€â”€â”€â”€â”€â”€â”€
        dormitorios = limpiar_y_convertir_a_numero(card.get("data-numhabitaciones"))

        if es_nuevo:
            resultados.append(
                f"\n*{nombre} (Ãtica â€“ Nuevo proyecto)*"
                f"\nğŸ“ {municipio_raw.title()}"
                f"\nğŸ”— [Ver promociÃ³n]({url_promo})"
            )
            continue

        if dormitorios is not None and dormitorios < HABITACIONES_MINIMAS:
            continue  # precios ya estÃ¡n â‰¤ 270 000 â‚¬ gracias al filtro de la URL

        resultados.append(
            f"\n*{nombre} (Ãtica)*"
            f"\nğŸ“ {municipio_raw.title()}"
            f"\nğŸ›ï¸ Dorms: {dormitorios if dormitorios else 'â€”'}"
            f"\nğŸ”— [Ver promociÃ³n]({url_promo})"
        )

        time.sleep(0.35)  # pausa suave para no saturar

    print(f"[DEBUG] ÃTICA filtradas â†’ {len(resultados)}", flush=True)
    return resultados