# scrapers/viacelere.py
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
import re, requests
from bs4 import BeautifulSoup
from utils import (
    HEADERS, LOCALIZACIONES_DESEADAS, HABITACIONES_MINIMAS,
    PRECIO_MAXIMO, limpiar_y_convertir_a_numero
)

LISTADO_URL      = "https://www.viacelere.com/promociones?provincia_id=46"
PROXIMAMENTE_URL = "https://www.viacelere.com/promociones/proximamente"

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _extraer_tarjetas(html: str) -> list[BeautifulSoup]:
    """Devuelve la lista de nodos <div class='card-promocion'> que haya en el HTML."""
    soup = BeautifulSoup(html, "html.parser")
    return soup.select("div.card-promocion")


def _procesar_tarjeta(card: BeautifulSoup, es_proximamente: bool) -> str | None:
    """Parsea una tarjeta y devuelve el bloque Markdown si pasa los filtros."""
    # ‚Äî t√≠tulo ‚Äî
    raw  = card.select_one("h2.title-size-4").get_text(" ", strip=True)
    nombre = re.sub(r"^\s*C[e√©]lere\s+", "", raw, flags=re.I).strip()

    # ‚Äî enlace ‚Äî
    link = card.find_parent("a") or card.select_one("a.button")
    url  = link["href"] if (link and link.has_attr("href")) else "SIN URL"

    # ‚Äî ubicaci√≥n, estado, dormitorios ‚Äî
    ubic, dorm_txt = None, None
    estado_txt     = "Pr√≥ximamente" if es_proximamente else None

    for p in card.select("div.desc p.paragraph-size--2"):
        txt_low = p.get_text(strip=True).lower()
        if "espa√±a" in txt_low:
            ubic = txt_low
        elif "dormitorio" in txt_low:
            dorm_txt = txt_low
        elif "comercializaci√≥n" in txt_low or "pr√≥ximamente" in txt_low:
            estado_txt = p.get_text(strip=True)

    # Filtrado por ubicaci√≥n
    if not (ubic and any(loc in ubic for loc in LOCALIZACIONES_DESEADAS)):
        return None

    # Si es ‚ÄúPr√≥ximamente‚Äù, no exigimos precio ni dormitorios
    if "pr√≥ximamente" in (estado_txt or "").lower():
        return (
            f"\n*{nombre} (V√≠a C√©lere ‚Äì Pr√≥ximamente)*"
            f"\nüìç {ubic.title()}"
            f"\nüîó [Ver promoci√≥n]({url})"
        )

    # ‚Äî precio + dormitorios (estado = En comercializaci√≥n) ‚Äî
    precio_tag = card.select_one("div.precio")
    precio_txt = precio_tag.get_text(strip=True) if precio_tag else None
    precio     = limpiar_y_convertir_a_numero(precio_txt)
    dorms      = limpiar_y_convertir_a_numero(dorm_txt)

    if dorms is None or dorms < HABITACIONES_MINIMAS:
        return None
    if precio is not None and precio > PRECIO_MAXIMO:
        return None

    return (
        f"\n*{nombre} (V√≠a C√©lere)*"
        f"\nüìç {ubic.title()}"
        f"\nüí∂ Desde: {precio:,}‚Ç¨" if precio else ""
        f"\nüõèÔ∏è Dorms: {dorms}"
        f"\nüîó [Ver promoci√≥n]({url})".replace(",", ".")
    )


def scrape() -> list[str]:
    resultados: list[str] = []

    # 1 ‚ñ∏ Listado normal (comercializaci√≥n)
    html = requests.get(LISTADO_URL, headers=HEADERS, timeout=30).text
    cards = _extraer_tarjetas(html)
    print(f"[DEBUG] V√çA C√âLERE (venta) ‚Üí {len(cards)} tarjetas", flush=True)

    for card in cards:
        bloque = _procesar_tarjeta(card, es_proximamente=False)
        if bloque:
            resultados.append(bloque)

    # 2 ‚ñ∏ Listado ‚ÄúPr√≥ximamente‚Äù
    html = requests.get(PROXIMAMENTE_URL, headers=HEADERS, timeout=30).text
    cards = _extraer_tarjetas(html)
    print(f"[DEBUG] V√çA C√âLERE (pr√≥x.) ‚Üí {len(cards)} tarjetas", flush=True)

    for card in cards:
        bloque = _procesar_tarjeta(card, es_proximamente=True)
        if bloque:
            resultados.append(bloque)

    print(f"[DEBUG] V√çA C√âLERE filtradas ‚Üí {len(resultados)}", flush=True)
    return resultados